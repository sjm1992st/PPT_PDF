  分布式技术：
	DataParallel (DP): 相同的初始化模型被复制多次，并且每次都被馈送 minibatch 的一部分。处理是并行完成的，所有设置在每个训练步骤结束时进行同步。
	TensorParallel (TP): 每个张量都被分成多个块，因此不是让整个张量驻留在单个 GPU 上，而是张量的每个分片都驻留在其指定的 GPU 上。在处理过程中，每个分片在不同的 GPU 上分别并行处理，最终结果在步骤结束时同步。这也被称作横向并行。
	PipelineParallel (PP) :模型在多个 GPU 上垂直（层级）拆分，因此只有模型的一个或多个层放置在单个 GPU 上。每个 GPU 并行处理管道的不同阶段，并处理一小部分批处理。
	零冗余优化器 (ZeRO): 也执行与 TP 有点类似的张量分片，除了整个张量会及时重建以进行前向或反向计算，因此不需要修改模型。它还支持各种卸载技术以补偿有限的 GPU 内存。

大模型微调方法：
 Lora:
 prompt-tuning:
 P-Tuning v2
 

现实世界的真实场景中，某些类别只有少量数据或少量标注数据，而对无标签数据进行标注将会消耗大量的时间和人力
少样本学习：小样本学习分为三类：模型微调、数据增强、迁移学习
        - 基于度量学习的方法：1）采用孪生网络，输入判断的query和少量标注样本中的一条样本，如果相似则和标注的样本属于同一类 （判断样本和标注样本的距离）
	- 数据增强：使用GAN/VAE/数据插值等生成训练数据
